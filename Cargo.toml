[package]
name = "ai_r"
version = "0.1.0"
edition = "2024"

[dependencies]
# The Framework
burn = { version = "0.19.1", features = ["wgpu", "train", "std"] }

# Serialization for saving models/configs
serde = { version = "1.0", features = ["derive"] }

# HuggingFace Tokenizers (Standard for LLMs)
tokenizers = { version = "0.19", features = ["http"] }

# Error handling
anyhow = "1.0"
